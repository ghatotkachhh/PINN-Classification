{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7849404,"sourceType":"datasetVersion","datasetId":4602950}],"dockerImageVersionId":30664,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\ndevice = \"cuda\"","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-03-16T10:16:16.552578Z","iopub.execute_input":"2024-03-16T10:16:16.552960Z","iopub.status.idle":"2024-03-16T10:16:16.911645Z","shell.execute_reply.started":"2024-03-16T10:16:16.552923Z","shell.execute_reply":"2024-03-16T10:16:16.910883Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"class config:\n    model = \"resnet18\"\n    model2 = \"resnet18\"\n    batchsize = 32\n    WEIGHT_DECAY = 0.01\n    EPOCHS = 20\nclass path:\n    maindir = \"/kaggle/input/gsoclensing/dataset/train\"\n    valid = \"/kaggle/input/gsoclensing/dataset/val\"","metadata":{"execution":{"iopub.status.busy":"2024-03-16T10:16:16.913012Z","iopub.execute_input":"2024-03-16T10:16:16.913362Z","iopub.status.idle":"2024-03-16T10:16:16.918361Z","shell.execute_reply.started":"2024-03-16T10:16:16.913339Z","shell.execute_reply":"2024-03-16T10:16:16.917367Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"pip install torchsummary","metadata":{"execution":{"iopub.status.busy":"2024-03-16T10:16:16.919246Z","iopub.execute_input":"2024-03-16T10:16:16.919504Z","iopub.status.idle":"2024-03-16T10:16:30.278572Z","shell.execute_reply.started":"2024-03-16T10:16:16.919482Z","shell.execute_reply":"2024-03-16T10:16:30.277154Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Collecting torchsummary\n  Downloading torchsummary-1.5.1-py3-none-any.whl.metadata (296 bytes)\nDownloading torchsummary-1.5.1-py3-none-any.whl (2.8 kB)\nInstalling collected packages: torchsummary\nSuccessfully installed torchsummary-1.5.1\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nfrom tqdm import tqdm\nimport timm\nimport torch.nn as nn\nfrom torchsummary import summary\nfrom torchvision import transforms\nimport time\nfrom torch.utils.data import DataLoader\nimport torch.nn.functional as F\nfrom sklearn.metrics import roc_curve, auc\n","metadata":{"execution":{"iopub.status.busy":"2024-03-16T10:16:30.281547Z","iopub.execute_input":"2024-03-16T10:16:30.281941Z","iopub.status.idle":"2024-03-16T10:16:38.237771Z","shell.execute_reply.started":"2024-03-16T10:16:30.281911Z","shell.execute_reply":"2024-03-16T10:16:38.236924Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"data = np.load('/kaggle/input/gsoclensing/dataset/train/no/5955.npy')","metadata":{"execution":{"iopub.status.busy":"2024-03-16T10:16:38.238902Z","iopub.execute_input":"2024-03-16T10:16:38.239450Z","iopub.status.idle":"2024-03-16T10:16:38.336464Z","shell.execute_reply.started":"2024-03-16T10:16:38.239420Z","shell.execute_reply":"2024-03-16T10:16:38.335576Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"data.shape","metadata":{"execution":{"iopub.status.busy":"2024-03-16T10:16:38.337695Z","iopub.execute_input":"2024-03-16T10:16:38.338046Z","iopub.status.idle":"2024-03-16T10:16:38.345450Z","shell.execute_reply.started":"2024-03-16T10:16:38.338018Z","shell.execute_reply":"2024-03-16T10:16:38.344381Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"(1, 150, 150)"},"metadata":{}}]},{"cell_type":"code","source":"train_data = {}\nfor i in (range(len(os.listdir(path.maindir)))):\n    for j in tqdm(os.listdir(os.path.join(path.maindir,os.listdir(path.maindir)[i]))):\n        train_data[os.path.join(os.path.join(path.maindir,os.listdir(path.maindir)[i],j))]=i\n        \nvalid_data = {}\nfor i in (range(len(os.listdir(path.valid)))):\n    for j in tqdm(os.listdir(os.path.join(path.valid,os.listdir(path.valid)[i]))):\n        valid_data[os.path.join(os.path.join(path.valid,os.listdir(path.valid)[i],j))]=i\n","metadata":{"execution":{"iopub.status.busy":"2024-03-16T10:16:38.346677Z","iopub.execute_input":"2024-03-16T10:16:38.347003Z","iopub.status.idle":"2024-03-16T10:16:55.125207Z","shell.execute_reply.started":"2024-03-16T10:16:38.346960Z","shell.execute_reply":"2024-03-16T10:16:55.124339Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"100%|██████████| 10000/10000 [00:03<00:00, 2594.59it/s]\n100%|██████████| 10000/10000 [00:03<00:00, 2609.51it/s]\n100%|██████████| 10000/10000 [00:03<00:00, 2627.98it/s]\n100%|██████████| 2500/2500 [00:00<00:00, 2549.13it/s]\n100%|██████████| 2500/2500 [00:00<00:00, 2507.26it/s]\n100%|██████████| 2500/2500 [00:00<00:00, 2759.45it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"imgtrans = transforms.Compose([\n    transforms.ToPILImage(mode='L'),\n    transforms.ToTensor(),\n    transforms.Normalize((0.5,),(0.5,))\n]\n)","metadata":{"execution":{"iopub.status.busy":"2024-03-16T10:16:55.126414Z","iopub.execute_input":"2024-03-16T10:16:55.126696Z","iopub.status.idle":"2024-03-16T10:16:55.131432Z","shell.execute_reply.started":"2024-03-16T10:16:55.126672Z","shell.execute_reply":"2024-03-16T10:16:55.130544Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"class CustomDataset():\n    def __init__(self,dictt,trans):\n        self.trans = trans\n        self.dic = dictt\n    def __len__(self):\n        return len(self.dic)\n    def __getitem__(self,idx):\n        keys = list(self.dic)[idx]\n        data = np.load(keys)\n        data = torch.tensor(data)\n        data = self.trans(data)\n        values = list(self.dic.values())[idx]\n        return {\n            \"data\":torch.tensor(data,dtype = torch.float32),\n            \"value\":torch.tensor(values)\n        }\n\n    \n            ","metadata":{"execution":{"iopub.status.busy":"2024-03-16T10:16:55.132672Z","iopub.execute_input":"2024-03-16T10:16:55.133213Z","iopub.status.idle":"2024-03-16T10:16:55.142454Z","shell.execute_reply.started":"2024-03-16T10:16:55.133185Z","shell.execute_reply":"2024-03-16T10:16:55.141602Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"custom = CustomDataset(train_data,imgtrans)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-16T10:16:55.145789Z","iopub.execute_input":"2024-03-16T10:16:55.146066Z","iopub.status.idle":"2024-03-16T10:16:55.154962Z","shell.execute_reply.started":"2024-03-16T10:16:55.146043Z","shell.execute_reply":"2024-03-16T10:16:55.154129Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"len(custom)","metadata":{"execution":{"iopub.status.busy":"2024-03-16T10:16:55.155958Z","iopub.execute_input":"2024-03-16T10:16:55.156202Z","iopub.status.idle":"2024-03-16T10:16:55.165712Z","shell.execute_reply.started":"2024-03-16T10:16:55.156181Z","shell.execute_reply":"2024-03-16T10:16:55.165013Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"30000"},"metadata":{}}]},{"cell_type":"code","source":"custom[0][\"data\"]","metadata":{"execution":{"iopub.status.busy":"2024-03-16T10:16:55.166729Z","iopub.execute_input":"2024-03-16T10:16:55.167001Z","iopub.status.idle":"2024-03-16T10:16:55.264151Z","shell.execute_reply.started":"2024-03-16T10:16:55.166958Z","shell.execute_reply":"2024-03-16T10:16:55.263354Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_33/3178738305.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  \"data\":torch.tensor(data,dtype = torch.float32),\n","output_type":"stream"},{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"tensor([[[-0.9686, -0.9843, -0.9843,  ..., -0.9765, -0.9922, -0.9843],\n         [-0.9765, -0.9843, -0.9686,  ..., -0.9765, -0.9843, -0.9765],\n         [-0.9843, -0.9765, -0.9686,  ..., -0.9765, -0.9843, -0.9922],\n         ...,\n         [-0.9686, -0.9922, -0.9765,  ..., -0.9843, -0.9843, -0.9843],\n         [-0.9765, -0.9922, -0.9843,  ..., -0.9922, -0.9765, -0.9686],\n         [-0.9686, -0.9686, -0.9686,  ..., -0.9843, -0.9922, -0.9686]]])"},"metadata":{}}]},{"cell_type":"code","source":"def deltamat(shape):\n    kk = np.zeros((shape,shape))\n    for i in range(shape):\n        for j in range(shape):\n            kk[i][j] = (((i+1)**2)+((j+1)**2))**0.5\n    return torch.tensor(kk,dtype = torch.float32)\npositiontensor = deltamat(224)\npositiontensor.to(\"cuda\")","metadata":{"execution":{"iopub.status.busy":"2024-03-16T10:16:55.265115Z","iopub.execute_input":"2024-03-16T10:16:55.265367Z","iopub.status.idle":"2024-03-16T10:16:55.771945Z","shell.execute_reply.started":"2024-03-16T10:16:55.265345Z","shell.execute_reply":"2024-03-16T10:16:55.771050Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"tensor([[  1.4142,   2.2361,   3.1623,  ..., 222.0023, 223.0022, 224.0022],\n        [  2.2361,   2.8284,   3.6056,  ..., 222.0090, 223.0090, 224.0089],\n        [  3.1623,   3.6056,   4.2426,  ..., 222.0203, 223.0202, 224.0201],\n        ...,\n        [222.0023, 222.0090, 222.0203,  ..., 313.9554, 314.6633, 315.3728],\n        [223.0022, 223.0090, 223.0202,  ..., 314.6633, 315.3696, 316.0775],\n        [224.0022, 224.0089, 224.0201,  ..., 315.3728, 316.0775, 316.7838]],\n       device='cuda:0')"},"metadata":{}}]},{"cell_type":"code","source":"class SimpleModel(nn.Module):\n    def __init__(self):\n        super(SimpleModel,self).__init__()\n        self.resnet = timm.create_model(\n            config.model,\n            pretrained = True,\n            drop_rate = 0.1\n        )\n        self.resnet.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n        self.resnet.fc = nn.Linear(in_features=512, out_features=3, bias=True)\n    def forward(self,x):\n        x = self.resnet(x)\n        return x\n        ","metadata":{"execution":{"iopub.status.busy":"2024-03-16T10:16:55.773076Z","iopub.execute_input":"2024-03-16T10:16:55.773370Z","iopub.status.idle":"2024-03-16T10:16:55.780210Z","shell.execute_reply.started":"2024-03-16T10:16:55.773346Z","shell.execute_reply":"2024-03-16T10:16:55.779349Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"class SimpleModel(nn.Module):\n    def __init__(self,positionmat,batchsize = config.batchsize):\n        super(SimpleModel,self).__init__()\n        self.positionmat = positionmat\n        self.batchsize = batchsize\n        self.encoder = timm.create_model(\n            config.model1,\n            pretrained = True,\n            drop_rate = 0.1\n        )\n        self.encoder.conv1 = Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n        self.coeff = nn.Sequential(\n            nn.Flatten(start_dim=1),\n            nn.Linear(1000,150*150)\n        )\n        self.doosramodel = timm.create_model(\n            config.model2,\n            pretrained = True,\n            drop_rate = 0.1\n        )\n        self.doosramodel.conv1 = Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n        self.fc = nn.Sequential(\n            nn.Flatten(),\n            nn.Linear(1000,3)\n        )\n                \n    def forward(self,x):\n        k = self.resnet(x)\n        k = self.coeff(k)\n        #print(k.shape)\n        k = k.reshape(self.batchsize,224,224)\n        angulardistort = k*self.positionmat\n        print(angulardistort.shape)\n        sourced_image = x-angulardistort\n        features = self.doosramodel(sourced_image)\n        prob = self.fc(features)\n        return prob\n        ","metadata":{"execution":{"iopub.status.busy":"2024-03-16T10:16:55.781653Z","iopub.execute_input":"2024-03-16T10:16:55.781947Z","iopub.status.idle":"2024-03-16T10:16:55.792762Z","shell.execute_reply.started":"2024-03-16T10:16:55.781919Z","shell.execute_reply":"2024-03-16T10:16:55.791912Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"'class SimpleModel(nn.Module):\\n    def __init__(self,positionmat,batchsize = config.batchsize):\\n        super(SimpleModel,self).__init__()\\n        self.positionmat = positionmat\\n        self.batchsize = batchsize\\n        self.resnet = timm.create_model(\\n            config.model1,\\n            pretrained = True,\\n            drop_rate = 0.1\\n        )\\n        self.coeff = nn.Sequential(\\n            nn.Flatten(),\\n            nn.Linear(1000,224*224)\\n        )\\n        self.doosramodel = timm.create_model(\\n            config.model2,\\n            pretrained = True,\\n            drop_rate = 0.1\\n        )\\n        self.fc = nn.Sequential(\\n            nn.Flatten(),\\n            nn.Linear(1000,3)\\n        )\\n                \\n    def forward(self,x):\\n        k = self.resnet(x)\\n        k = self.coeff(k)\\n        #print(k.shape)\\n        k = k.reshape(self.batchsize,224,224)\\n        angulardistort = k*self.positionmat\\n        print(angulardistort.shape)\\n        sourced_image = x-angulardistort\\n        features = self.doosramodel(sourced_image)\\n        prob = self.fc(features)\\n        return prob\\n        '"},"metadata":{}}]},{"cell_type":"code","source":"simple = SimpleModel()\nprint(simple)\nxx = torch.randn(size=(1,1,224,224))\n\nsimple(xx)","metadata":{"execution":{"iopub.status.busy":"2024-03-16T10:16:55.793815Z","iopub.execute_input":"2024-03-16T10:16:55.794085Z","iopub.status.idle":"2024-03-16T10:16:56.705931Z","shell.execute_reply.started":"2024-03-16T10:16:55.794062Z","shell.execute_reply":"2024-03-16T10:16:56.705026Z"},"trusted":true},"execution_count":16,"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/46.8M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b6f8172164984876b61a2a3f9900bb20"}},"metadata":{}},{"name":"stdout","text":"SimpleModel(\n  (resnet): ResNet(\n    (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act1): ReLU(inplace=True)\n    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n    (layer1): Sequential(\n      (0): BasicBlock(\n        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (drop_block): Identity()\n        (act1): ReLU(inplace=True)\n        (aa): Identity()\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n      )\n      (1): BasicBlock(\n        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (drop_block): Identity()\n        (act1): ReLU(inplace=True)\n        (aa): Identity()\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n      )\n    )\n    (layer2): Sequential(\n      (0): BasicBlock(\n        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (drop_block): Identity()\n        (act1): ReLU(inplace=True)\n        (aa): Identity()\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n        (downsample): Sequential(\n          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): BasicBlock(\n        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (drop_block): Identity()\n        (act1): ReLU(inplace=True)\n        (aa): Identity()\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n      )\n    )\n    (layer3): Sequential(\n      (0): BasicBlock(\n        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (drop_block): Identity()\n        (act1): ReLU(inplace=True)\n        (aa): Identity()\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n        (downsample): Sequential(\n          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): BasicBlock(\n        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (drop_block): Identity()\n        (act1): ReLU(inplace=True)\n        (aa): Identity()\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n      )\n    )\n    (layer4): Sequential(\n      (0): BasicBlock(\n        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (drop_block): Identity()\n        (act1): ReLU(inplace=True)\n        (aa): Identity()\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n        (downsample): Sequential(\n          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): BasicBlock(\n        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (drop_block): Identity()\n        (act1): ReLU(inplace=True)\n        (aa): Identity()\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n      )\n    )\n    (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n    (fc): Linear(in_features=512, out_features=3, bias=True)\n  )\n)\n","output_type":"stream"},{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"tensor([[ 0.0025, -0.1034,  0.0846]], grad_fn=<AddmmBackward0>)"},"metadata":{}}]},{"cell_type":"code","source":"simple(custom[0][\"data\"].unsqueeze(0))","metadata":{"execution":{"iopub.status.busy":"2024-03-16T10:16:56.707073Z","iopub.execute_input":"2024-03-16T10:16:56.707368Z","iopub.status.idle":"2024-03-16T10:16:56.767444Z","shell.execute_reply.started":"2024-03-16T10:16:56.707342Z","shell.execute_reply":"2024-03-16T10:16:56.766484Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_33/3178738305.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  \"data\":torch.tensor(data,dtype = torch.float32),\n","output_type":"stream"},{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"tensor([[0.3846, 0.1204, 0.1341]], grad_fn=<AddmmBackward0>)"},"metadata":{}}]},{"cell_type":"code","source":"traindataset = CustomDataset(train_data,imgtrans)\nvaliddataset  =CustomDataset(valid_data,imgtrans)\n\ntrainloader = DataLoader(traindataset,batch_size = 32,shuffle = True)\ntestloader = DataLoader(validdataset,batch_size = 32,shuffle = True)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-16T10:16:56.768519Z","iopub.execute_input":"2024-03-16T10:16:56.768792Z","iopub.status.idle":"2024-03-16T10:16:56.773917Z","shell.execute_reply.started":"2024-03-16T10:16:56.768769Z","shell.execute_reply":"2024-03-16T10:16:56.773017Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"from torch.optim.lr_scheduler import OneCycleLR\n","metadata":{"execution":{"iopub.status.busy":"2024-03-16T10:16:56.775014Z","iopub.execute_input":"2024-03-16T10:16:56.775267Z","iopub.status.idle":"2024-03-16T10:16:56.783124Z","shell.execute_reply.started":"2024-03-16T10:16:56.775245Z","shell.execute_reply":"2024-03-16T10:16:56.782331Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"def trainer(model,trainloader,optimizer,criterion,device):\n    model.train()\n    iterationloss = 0\n    counter = 0\n    for data in tqdm(trainloader):\n        message = data['data'].to(device)\n        target = data['value'].to(device).squeeze()\n        optimizer.zero_grad()\n        out = model(message)\n        loss = criterion(F.log_softmax(out, dim=1), target)\n        loss.backward()\n        optimizer.step()\n        iterationloss+=loss.item()*message.shape[0]\n        counter+=message.shape[0]\n    return iterationloss/counter","metadata":{"execution":{"iopub.status.busy":"2024-03-16T10:16:56.784091Z","iopub.execute_input":"2024-03-16T10:16:56.784352Z","iopub.status.idle":"2024-03-16T10:16:56.793775Z","shell.execute_reply.started":"2024-03-16T10:16:56.784329Z","shell.execute_reply":"2024-03-16T10:16:56.793057Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"def tester(model, testloader, criterion, device):\n    model.eval()\n    iteration_loss = 0\n    counter = 0\n    correct_predictions = 0\n    \n    y_true = []\n    y_scores = []\n\n    for data in tqdm(testloader):\n        message = data['data'].to(device)\n        target = data['value'].to(device).squeeze()\n        \n        with torch.no_grad():\n            out = model(message)\n            loss = criterion(F.log_softmax(out, dim=1), target)\n            iteration_loss += loss.item() * message.shape[0]\n            \n            # Count correct predictions\n            predicted_classes = torch.argmax(F.log_softmax(out, dim=1), dim=1)\n            correct_predictions += (predicted_classes == target).sum().item()\n            \"\"\"y_true.extend(target.cpu().numpy())\n            y_scores.extend(out.cpu().numpy())\"\"\"\n\n        counter += message.shape[0]\n\n    accuracy = correct_predictions / counter\n    print(\"Accuracy:\", accuracy)\n    return iteration_loss / counter\n","metadata":{"execution":{"iopub.status.busy":"2024-03-16T10:16:56.795015Z","iopub.execute_input":"2024-03-16T10:16:56.795315Z","iopub.status.idle":"2024-03-16T10:16:56.808119Z","shell.execute_reply.started":"2024-03-16T10:16:56.795287Z","shell.execute_reply":"2024-03-16T10:16:56.807375Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"meramodel = SimpleModel()\nmeramodel.to(device)\noptimizer = torch.optim.RAdam(meramodel.parameters(),lr = 0.1)\ncriterion = nn.CrossEntropyLoss()\nscheduler = scheduler = OneCycleLR(\n        optimizer,\n        max_lr=1e-1,\n        epochs=config.EPOCHS,\n        steps_per_epoch=938,\n        pct_start=0.1,\n        anneal_strategy=\"cos\",\n        final_div_factor=100)","metadata":{"execution":{"iopub.status.busy":"2024-03-16T10:16:56.809186Z","iopub.execute_input":"2024-03-16T10:16:56.809454Z","iopub.status.idle":"2024-03-16T10:16:57.165095Z","shell.execute_reply.started":"2024-03-16T10:16:56.809431Z","shell.execute_reply":"2024-03-16T10:16:57.164268Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"trainloss =[]\nvalloss = []\nbestloss = np.inf\nfor i in range(config.EPOCHS):\n    print(\"Epoch no. =\" ,i+1)\n    print(\"-\"*80)\n    trainl = trainer(meramodel,trainloader,optimizer,criterion,device)\n    vall = tester(meramodel,testloader,criterion,device)\n    trainloss.append(trainl)\n    valloss.append(vall)\n    scheduler.step(vall)\n    print(\"TrainLoss = \",trainl,\" \",\"ValidationLoss = \",vall)\n    lr=scheduler.get_last_lr()[0]\n    print(\"lr = \",lr)\n    if bestloss>vall:\n        bestloss = vall\n        torch.save({\n            'model':meramodel.state_dict(),\n            'optimizer':optimizer.state_dict()},\n        './Bestmodel.model'\n        )\n        print(\"Best Model Saved\")\n    print(\"=\"*80)","metadata":{"execution":{"iopub.status.busy":"2024-03-16T10:16:57.166388Z","iopub.execute_input":"2024-03-16T10:16:57.167160Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Epoch no. = 1\n--------------------------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/938 [00:00<?, ?it/s]/tmp/ipykernel_33/3178738305.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  \"data\":torch.tensor(data,dtype = torch.float32),\n 70%|███████   | 657/938 [04:18<01:51,  2.52it/s]","output_type":"stream"}]},{"cell_type":"code","source":"train_loop()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class LensingLayer(nn.Module):\n    def __init__(self,)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nx  =torch.tensor([[1,1],[1,1]])\ny = torch.tensor([[2,3],[4,6]])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x*y","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}